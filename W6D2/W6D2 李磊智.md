# Discussion: ways of reducing cache miss

## **Preceding Knowledge**

### Basic classification of miss:
1. Compulsory: Brought in by the initialization of cache. 
2. Capacity: Due to the limitation of the cache size, blocks will be discarded and later retrieved during the program execution.
3. Conflict: If a set is set associative or direct mapped, conflict misses will occur when a block may be discarded and later retrieved if too many blocks map to its set.
----

## **Optimization Practice**
### **review**
 1. Larger Block Size  
The total miss rate-block size curve shows a tendency of first decline and then rise. The decline is a result of a reduction in compulsory miss since fewer blocks are required in cache initialization. To understand the rise we must consider the effect of conflict miss. With larger block size and the same cache size, the number of blocks will fall, increasing the possibility of different blocks share the same position in the cache. And such effect is more severe in small cache size. 
 2. Higher Associativity  
 A higher associativity append the effective capacity pf the cache. If the program use two pieces of data mapped into the same index, the data will be moved between cache and memory constantly.With Higher associativity, conflict miss rate can be effectively reduced.However, a higher associaticity comes at the expense of increased hit time since the select logic is more complex.
### **new**
 3. Victim Cache  
 The victim cache refers to a buffer which collects the replaced blocks from the cache temporarily. Such implemetation is based on the philosophy of combining the speed of direct mapped cache and the associativity of full associative cache. It is also based on the experience that the most often replaced caches are the ones used most recently. Such observation argues for the utility of Victim Cache.  
----
**The Connection bewteen Victim Cache And Store Buffer**  
 Similarity:  
- Both structures keep the up-to-date version of the data in the system.
- Both structures keeps information that will eventually be written into memory.
- Both structures helps improve performance. 

Difference:  
- The data in the victim cache is abandaned by cache while data in the store buffer is from the commmitments of store instructions. 
- Victim cache improves performance by reducing cache miss, store buffer improves performance by bypassing values to load instruction and somtimes(in no sequential store buffer) by allowing load instruction execute  when store instructions ahead of them are not ready.
- The content in victim cache will be replaced by newly abandoned cache lines automatically while entries in store buffer will be released only when the values it used are ready and be commited into the memory.
-----
4. Pseodo-associative Cache  
The idea of pseodo-associative cache resembles the idea of open addresing method in hash table collision. It is usually used in cache with more and smaller cache sets. We main idea of pseodo-associative cache is that when we meet a cache miss we try another block set in a specific location. The locatio is specified by reversing the highest bit of the cache index. For example a index of 1101 will be transformed to 0101. In this way, even thouth we don`t change the structure of cache, we improve the associativity of cache lines.
